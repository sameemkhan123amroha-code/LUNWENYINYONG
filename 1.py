import streamlit as st
import pandas as pd
from pypdf import PdfReader
from io import BytesIO
import openai
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.schema import Document
from sklearn.metrics.pairwise import cosine_similarity
import re
import os

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="å…¨èƒ½è®ºæ–‡åŠ©æ‰‹ (æ™ºè°±ä¿®å¤ç‰ˆ)", layout="wide")

st.markdown("""
<style>
    .block-container { padding-top: 20px; }
    .stButton>button { width: 100%; border-radius: 6px; height: 3em; font-weight: 600; }
    .interactive-sent { cursor: pointer; border-bottom: 2px solid #e0e0e0; padding: 0 2px; transition: all 0.2s; line-height: 1.8; }
    .interactive-sent:hover { background-color: #fff8e1; border-bottom-color: #ffc107; }
    .info-tooltip { display: none; position: fixed; background: #ffffff; border: 1px solid #d1d5da; box-shadow: 0 10px 30px rgba(0,0,0,0.15); padding: 16px; z-index: 999999; width: 400px; border-radius: 8px; font-family: sans-serif; font-size: 14px; line-height: 1.5; color: #24292e; }
    .tooltip-header { display: flex; justify-content: space-between; margin-bottom: 8px; border-bottom: 1px solid #eaecef; padding-bottom: 8px;}
    .tooltip-source { font-weight: 700; color: #0366d6; font-size: 13px; }
    .tooltip-score { font-weight: 700; font-size: 13px; }
    .tooltip-content { background: #f6f8fa; padding: 12px; border-radius: 6px; font-size: 13px; max-height: 200px; overflow-y: auto; color: #444; border: 1px solid #eaecef;}
    .spacer { height: 250px; }
</style>
""", unsafe_allow_html=True)

# --- 2. æ ¸å¿ƒé€»è¾‘å‡½æ•° ---

# å°è¯•å¯¼å…¥æœ¬åœ°æ¨¡å‹åº“ï¼ˆä»…ä½œä¸ºå¤‡ç”¨ï¼Œä¸å¼ºåˆ¶ï¼‰
try:
    from langchain_community.embeddings import HuggingFaceEmbeddings
except ImportError:
    HuggingFaceEmbeddings = None

def get_pdf_text(pdf_docs):
    text_data = []
    for pdf in pdf_docs:
        try:
            pdf_reader = PdfReader(pdf)
            text = ""
            for page in pdf_reader.pages:
                t = page.extract_text()
                if t: text += t
            text_data.append({"filename": pdf.name, "text": text})
        except Exception as e:
            st.error(f"âš ï¸ æ–‡ä»¶ {pdf.name} è¯»å–å¤±è´¥: {e}")
    return text_data

def get_vectorstore(text_data, use_online_embed, api_key, api_base, provider):
    """
    æ„å»ºå‘é‡åº“
    """
    documents = []
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
    for item in text_data:
        chunks = text_splitter.split_text(item["text"])
        for chunk in chunks:
            documents.append(Document(page_content=chunk, metadata={"source": item["filename"]}))
    
    embeddings = None
    
    # --- æ ¸å¿ƒä¿®æ”¹ï¼šåœ¨çº¿ Embedding é€»è¾‘ ---
    if use_online_embed:
        if not api_key:
            st.error("âŒ ä½¿ç”¨åœ¨çº¿ Embedding éœ€è¦æä¾› API Keyï¼")
            st.stop()
        
        # æ™ºèƒ½åˆ¤æ–­ Embedding æ¨¡å‹åç§°
        embed_model_name = "text-embedding-3-small" # OpenAI é»˜è®¤
        if "Zhipu" in provider:
            embed_model_name = "embedding-2" # æ™ºè°±ä¸“ç”¨ Embedding æ¨¡å‹
        
        try:
            # ä½¿ç”¨ LangChain çš„ OpenAI å…¼å®¹æ¥å£è°ƒç”¨æ™ºè°± Embedding
            # ğŸ’¡ã€å…³é”®ä¿®å¤ã€‘ï¼šå¢åŠ  chunk_size=16 å‚æ•°
            # æ™ºè°± API é™åˆ¶å•æ¬¡è¯·æ±‚æœ€å¤§ 64 æ¡ï¼ŒLangChain é»˜è®¤æ˜¯ 1000ï¼Œå¿…é¡»æ”¹æˆå°äº 64
            embeddings = OpenAIEmbeddings(
                openai_api_key=api_key, 
                openai_api_base=api_base,
                model=embed_model_name,
                chunk_size=16  # <--- è¿™é‡Œæ˜¯ä¿®å¤ 1214 é”™è¯¯çš„å…³é”®
            )
        except Exception as e:
            st.error(f"âŒ åœ¨çº¿ Embedding åˆå§‹åŒ–å¤±è´¥: {e}")
            st.stop()
            
    else:
        # æœ¬åœ°æ¨¡å‹é€»è¾‘ (å¤‡ç”¨)
        if HuggingFaceEmbeddings is None:
            st.error("âŒ ç¼ºå°‘ sentence-transformers åº“ï¼Œæ— æ³•ä½¿ç”¨æœ¬åœ°æ¨¡å‹ã€‚å»ºè®®å‹¾é€‰ä¸Šæ–¹ 'ä½¿ç”¨åœ¨çº¿ Embedding'ã€‚")
            st.stop()
        try:
            os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com' # å›½å†…é•œåƒ
            embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
        except Exception as e:
            st.error(f"âŒ æœ¬åœ°æ¨¡å‹åŠ è½½å¤±è´¥: {e}ã€‚å»ºè®®å‹¾é€‰ä¸Šæ–¹ 'ä½¿ç”¨åœ¨çº¿ Embedding' æ”¹ç”¨æ™ºè°±æ¥å£ã€‚")
            st.stop()

    # è¿™é‡Œä¼šè§¦å‘æ‰¹é‡çš„ Embedding è¯·æ±‚ï¼Œchunk_size=16 ä¼šç¡®ä¿ä¸è¶…é™
    vectorstore = FAISS.from_documents(documents, embeddings)
    return vectorstore, embeddings

# --- 3. ç•Œé¢å¸ƒå±€ ---

st.title("ğŸ¤– æ™ºèƒ½è®ºæ–‡åŠ©æ‰‹ (æ™ºè°±ä¿®å¤ç‰ˆ)")

# --- é…ç½®åŒº ---
with st.container():
    col_config, col_upload = st.columns([1, 1.2])
    
    with col_config:
        with st.expander("ğŸ› ï¸ æ¨¡å‹å‚æ•°é…ç½®", expanded=True):
            provider = st.selectbox(
                "1. é€‰æ‹©å¤§æ¨¡å‹å‚å•†",
                [
                    "Zhipu AI (æ™ºè°±GLM)",   # æ¨è
                    "DeepSeek (æ·±åº¦æ±‚ç´¢)", 
                    "OpenAI (GPT-4o)", 
                    "Kimi (æœˆä¹‹æš—é¢)", 
                    "Custom (è‡ªå®šä¹‰)"
                ]
            )
            
            # é¢„è®¾å‚æ•°
            p_url = "https://open.bigmodel.cn/api/paas/v4/"
            p_model = "glm-4"
            
            # é»˜è®¤å‹¾é€‰åœ¨çº¿ Embedding
            default_use_online = True 
            
            if "Zhipu" in provider:
                p_url = "https://open.bigmodel.cn/api/paas/v4/"
                p_model = "glm-4"
                default_use_online = True # æ™ºè°±é»˜è®¤ä½¿ç”¨åœ¨çº¿ï¼Œçœå»æœ¬åœ°éº»çƒ¦
            elif "DeepSeek" in provider:
                p_url = "https://api.deepseek.com/v1" # è‡ªåŠ¨ä¿®æ­£ /v1
                p_model = "deepseek-chat"
                default_use_online = False # DeepSeek æ²¡æœ‰ embeddingï¼Œé»˜è®¤èµ°æœ¬åœ°
            elif "OpenAI" in provider:
                p_url = "https://api.openai.com/v1"
                p_model = "gpt-4o"
                default_use_online = True
            elif "Kimi" in provider:
                p_url = "https://api.moonshot.cn/v1"
                p_model = "moonshot-v1-8k"
                default_use_online = False
            
            api_base = st.text_input("Base URL", value=p_url)
            model_name = st.text_input("Model Name", value=p_model)
            api_key = st.text_input("API Key", type="password", placeholder="è¾“å…¥ Key...")

            st.markdown("---")
            
            # å…³é”®å¤é€‰æ¡†
            use_online_embed = st.checkbox(
                "ä½¿ç”¨åœ¨çº¿ Embedding (æ™ºè°±/OpenAI ç”¨æˆ·å¼ºçƒˆæ¨èå‹¾é€‰)", 
                value=default_use_online,
                help="å‹¾é€‰åå°†ä½¿ç”¨å‚å•†çš„ API è¿›è¡Œå‘é‡åŒ–ï¼Œæ— éœ€ä¸‹è½½æœ¬åœ°æ¨¡å‹ã€‚æ™ºè°±ç”¨æˆ·è¯·åŠ¡å¿…å‹¾é€‰ï¼"
            )
            
            if use_online_embed and "Zhipu" in provider:
                st.caption("âœ… å·²å¯ç”¨æ™ºè°± `embedding-2`ï¼Œå·²ä¿®å¤ 64 æ¡é™åˆ¶é—®é¢˜ã€‚")

    with col_upload:
        uploaded_files = st.file_uploader("ğŸ“‚ å¯¼å…¥ PDF è®ºæ–‡", accept_multiple_files=True, type=['pdf'])
        if uploaded_files:
            if 'processed_data' not in st.session_state or st.session_state.get('file_count') != len(uploaded_files):
                with st.spinner("ğŸ“„ è§£æ PDF ä¸­..."):
                    st.session_state.processed_data = get_pdf_text(uploaded_files)
                    st.session_state.file_count = len(uploaded_files)
                st.success(f"âœ… å·²åŠ è½½ {len(uploaded_files)} ç¯‡è®ºæ–‡")

st.divider()

# --- Excel æ•´ç† ---
if st.session_state.get('processed_data'):
    col_btn, col_dl = st.columns([1, 4])
    with col_btn:
        do_excel = st.button("ğŸ“Š ä¸€é”®æ•´ç†æˆ EXCEL")
    
    if do_excel:
        if not api_key:
            st.error("âŒ è¯·å…ˆè¾“å…¥ API Key")
        else:
            with st.spinner(f"æ­£åœ¨ä½¿ç”¨ {model_name} é˜…è¯»å¹¶æ€»ç»“..."):
                try:
                    llm = ChatOpenAI(base_url=api_base, api_key=api_key, model=model_name, temperature=0.1)
                    summary_list = []
                    prog = st.progress(0)
                    total = len(st.session_state.processed_data)
                    for i, item in enumerate(st.session_state.processed_data):
                        prompt = f"ä»»åŠ¡ï¼šç”¨ä¸­æ–‡æ¦‚æ‹¬è¿™ç¯‡è®ºæ–‡çš„æ ¸å¿ƒå†…å®¹ã€‚\nã€é™åˆ¶ã€‘ï¼šä¸¥æ ¼æ§åˆ¶åœ¨ 20 ä¸ªæ±‰å­—ä»¥å†…ï¼ç›´æ¥å†™ç»“è®ºã€‚\nè®ºæ–‡ç‰‡æ®µï¼š{item['text'][:2000]}"
                        res = llm.invoke(prompt)
                        summary_list.append({"è®ºæ–‡åç§°": item["filename"], "è®ºæ–‡å¤§è‡´æ„æ€": res.content.strip()})
                        prog.progress((i+1)/total)
                    
                    df = pd.DataFrame(summary_list)
                    out = BytesIO()
                    with pd.ExcelWriter(out, engine='xlsxwriter') as writer:
                        df.to_excel(writer, index=False)
                        writer.sheets['Sheet1'].set_column('A:B', 40)
                    
                    with col_dl:
                        st.download_button("â¬‡ï¸ ä¸‹è½½ Excel", out.getvalue(), "è®ºæ–‡æ•´ç†.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
                    st.dataframe(df, height=200)
                except Exception as e:
                    st.error(f"API é”™è¯¯: {e}")

st.divider()

# --- ç»¼è¿°ç”Ÿæˆ ---
st.subheader("ğŸ“ æ™ºèƒ½ç»¼è¿°ç”Ÿæˆ (RAG + è¯­ä¹‰æ ¸æŸ¥)")

c1, c2 = st.columns([4, 1])
query = c1.text_input("è¾“å…¥æç¤ºè¯", placeholder="ä¾‹å¦‚ï¼šåœ°èšç‰©çš„æŠ—å‹å¼ºåº¦å½±å“å› ç´ ")
start_rag = c2.button("ğŸš€ ç”Ÿæˆç»¼è¿°")

if start_rag:
    if not api_key:
        st.error("âŒ è¯·å…ˆè¾“å…¥ API Key")
    elif not st.session_state.get('processed_data'):
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼  PDF")
    elif not query:
        st.warning("âš ï¸ è¯·è¾“å…¥æç¤ºè¯")
    else:
        with st.spinner("ğŸ” æ­£åœ¨æ£€ç´¢èµ„æ–™..."):
            try:
                # 1. æ£€ç´¢ (ä¼ å…¥ use_online_embed å‚æ•°)
                vectorstore, embed_model = get_vectorstore(
                    st.session_state.processed_data, 
                    use_online_embed, 
                    api_key, 
                    api_base, 
                    provider
                )
                
                docs = vectorstore.similarity_search(query, k=8)
                
                if not docs:
                    st.error("æœªæ‰¾åˆ°ç›¸å…³å†…å®¹ã€‚")
                    st.stop()
                
                context = "\n".join([f"ã€æ¥æº:{d.metadata['source']}ã€‘{d.page_content}" for d in docs])
                
                # 2. ç”Ÿæˆ
                with st.spinner(f"âœï¸ æ­£åœ¨ä½¿ç”¨ {model_name} æ’°å†™ç»¼è¿°..."):
                    llm_chat = ChatOpenAI(base_url=api_base, api_key=api_key, model=model_name, temperature=0.3)
                    sys_prompt = f"ä½ æ˜¯ä¸€ä¸ªå­¦æœ¯åŠ©æ‰‹ã€‚åŸºäºä»¥ä¸‹èµ„æ–™æ’°å†™å…³äºâ€œ{query}â€çš„ç»¼è¿°ã€‚\nè¦æ±‚ï¼š\n1. å¿ å®äºåŸæ–‡ã€‚\n2. å¥å°¾æ ‡æ³¨æ¥æº (æ–‡ä»¶å)ã€‚\n3. è¾“å‡ºçº¯ HTML (ä¸å« <html>)ï¼Œåˆ†æ®µè½ <p>ã€‚\nèµ„æ–™ï¼š\n{context}"
                    resp = llm_chat.invoke(sys_prompt)
                    raw_html = resp.content.replace("```html", "").replace("```", "")
                
                # 3. è¯­ä¹‰æ ¸æŸ¥
                sentences = re.split(r'(?<=[ã€‚ï¼ï¼Ÿ])', raw_html)
                html_parts = []
                stat = st.empty()
                
                for idx, sent in enumerate(sentences):
                    clean = re.sub(r'<[^>]+>', '', sent).strip()
                    if len(clean) < 5:
                        html_parts.append(sent)
                        continue
                    
                    evidence_docs = vectorstore.similarity_search(clean, k=1)
                    if evidence_docs:
                        doc = evidence_docs[0]
                        v1 = embed_model.embed_query(clean)
                        v2 = embed_model.embed_query(doc.page_content)
                        score = cosine_similarity([v1], [v2])[0][0] * 100
                        
                        safe_txt = doc.page_content[:300].replace('"', '&quot;').replace('\n', ' ')
                        span = f"""<span id="s_{idx}" class="interactive-sent" onclick="showTip('s_{idx}', '{doc.metadata['source']}', {round(score,1)}, '{safe_txt}')">{sent}</span>"""
                        html_parts.append(span)
                    else:
                        html_parts.append(sent)
                
                stat.empty()
                full_html = "".join(html_parts) + "<div class='spacer'></div>"
                
                js = """
                <div id="tip" class="info-tooltip">
                    <div class="tooltip-header"><span id="t-src" class="tooltip-source"></span><span id="t-score" class="tooltip-score"></span></div>
                    <div style="font-weight:bold;margin-bottom:5px">è¯­ä¹‰è¯æ®:</div>
                    <div id="t-txt" class="tooltip-content"></div>
                </div>
                <script>
                function showTip(id, src, sc, txt) {
                    var t = document.getElementById('tip');
                    var el = document.getElementById(id);
                    var r = el.getBoundingClientRect();
                    var scrollTop = window.pageYOffset || document.documentElement.scrollTop;
                    var scrollLeft = window.pageXOffset || document.documentElement.scrollLeft;
                    document.getElementById('t-src').innerText = 'ğŸ“„ ' + src;
                    document.getElementById('t-score').innerHTML = 'åŒ¹é…åº¦: <span style="color:' + (sc>75?'#2da44e':sc>60?'#d29922':'#cf222e') + '">' + sc + '%</span>';
                    document.getElementById('t-txt').innerHTML = txt;
                    t.style.display = 'block';
                    t.style.top = (scrollTop + r.bottom + 5) + 'px';
                    t.style.left = (scrollLeft + r.left) + 'px';
                    setTimeout(() => { document.addEventListener('click', function c(e) {
                        if(e.target.id !== id && !t.contains(e.target)) { t.style.display = 'none'; document.removeEventListener('click', c); }
                    })}, 100);
                }
                </script>
                """
                
                st.success("âœ… ç”Ÿæˆå®Œæ¯•ï¼")
                st.components.v1.html(f"<div style='font-family:sans-serif;padding:10px'>{full_html}</div>{js}", height=600, scrolling=True)
                
            except Exception as e:
                st.error(f"âŒ è¿è¡Œé”™è¯¯: {e}")